{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e99beda1-d7bb-4de3-916c-327d1f2d87e2",
    "_execution_state": "busy",
    "_uuid": "92a8330e090e0074e540f721894351f10a6946d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwang14\\AppData\\Local\\Continuum\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\jwang14\\AppData\\Local\\Continuum\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\jwang14\\AppData\\Local\\Continuum\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\Users\\jwang14\\AppData\\Local\\Continuum\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\jwang14\\AppData\\Local\\Continuum\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene\n",
      "Variation\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "train = pd.read_csv('input/training_variants')\n",
    "test = pd.read_csv('input/test_variants')\n",
    "trainx = pd.read_csv('input/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "testx = pd.read_csv('input/test_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "\n",
    "train = pd.merge(train, trainx, how='left', on='ID')\n",
    "y = train['Class'].values\n",
    "train = train.drop('Class', axis=1)\n",
    "\n",
    "test = pd.merge(test, testx, how='left', on='ID')\n",
    "pid = test['ID'].values\n",
    "\n",
    "for c in train.columns:\n",
    "    if train[c].dtype == 'object' and c !='Text':\n",
    "        lbl = preprocessing.LabelEncoder(); print(c)\n",
    "        lbl.fit(list(train[c].values) + list(test[c].values))\n",
    "        train[c+'_lbl_enc'] = lbl.transform(list(train[c].values))\n",
    "        test[c+'_lbl_enc'] = lbl.transform(list(test[c].values))\n",
    "    if train[c].dtype == 'object':\n",
    "        train[c+'_len'] = train[c].map(lambda x: len(str(x)))\n",
    "        train[c+'_words'] = train[c].map(lambda x: len(str(x).split(' ')))\n",
    "        \n",
    "        test[c+'_len'] = test[c].map(lambda x: len(str(x)))\n",
    "        test[c+'_words'] = test[c].map(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "class cust_regression_vals(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        x = x.drop(['Gene', 'Variation','ID','Text'],axis=1).values\n",
    "        return x\n",
    "\n",
    "class cust_txt_col(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        return x[self.key].apply(str)\n",
    "\n",
    "fp = pipeline.Pipeline([\n",
    "    ('union', pipeline.FeatureUnion(\n",
    "        n_jobs = -1,\n",
    "        transformer_list = [\n",
    "            ('standard', cust_regression_vals()),\n",
    "            ('pi1', pipeline.Pipeline([('Gene', cust_txt_col('Gene')), ('count_Gene', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd1', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "            ('pi2', pipeline.Pipeline([('Variation', cust_txt_col('Variation')), ('count_Variation', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd2', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "            #uncomment below for full score - disabling for Kaggle limits\n",
    "            #('pi3', pipeline.Pipeline([('Text', cust_txt_col('Text')), ('tfidf_Text', feature_extraction.text.TfidfVectorizer(ngram_range=(1, 2))), ('tsvd3', decomposition.TruncatedSVD(n_components=50, n_iter=25, random_state=12))]))\n",
    "        ])\n",
    "    )])\n",
    "\n",
    "train = fp.fit_transform(train); print(train.shape)\n",
    "test = fp.transform(test); print(test.shape)\n",
    "\n",
    "params = {\n",
    "    'eta': 0.02,\n",
    "    'max_depth': 5,\n",
    "    'objective': 'multi:softprob',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'num_class': 9,\n",
    "    'seed': 12,\n",
    "    'silent': True\n",
    "}\n",
    "y = y - 1 #fix for zero bound array\n",
    "fold = 5\n",
    "for i in range(fold):\n",
    "    x1, x2, y1, y2 = model_selection.train_test_split(train, y, test_size=0.18, random_state=i)\n",
    "    watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "    model = xgb.train(params, xgb.DMatrix(x1, y1), 1000,  watchlist, verbose_eval=50, early_stopping_rounds=50)\n",
    "    if i != 0:\n",
    "        pred += model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit) / fold\n",
    "    else:\n",
    "        pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit) / fold   \n",
    "\n",
    "print (pred)\n",
    "submission = pd.DataFrame(pred, columns=['class'+str(c+1) for c in range(9)])\n",
    "submission['ID'] = pid\n",
    "submission.to_csv('submission_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
